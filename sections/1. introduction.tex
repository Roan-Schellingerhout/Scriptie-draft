\documentclass[../main.tex]{subfiles}
\graphicspath{{\subfix{images/}}}

\begin{document}

\section{Introduction}
\subsection{Doelstelling en relevantie}
Het doel van dit onderzoek is om te kijken hoe snel (oftewel: na hoeveel gekeken video’s) het YouTube-aanbevelingsalgoritme een voorkeur krijgt voor complotvideo's. YouTube is met 34.6 miljard maandelijkse gebruikers de één na meestbezochte website op het internet, waardoor de impact van de website op de maatschappij niet onderschat kan worden \citep{neufeld_2021}. Er wordt content van alle categorieën geproduceerd en geconsumeerd. Echter, complotcontent begint een hoofdrol te spelen op YouTube. Alt-right (ook wel 'far-right') en complotkanalen krijgen een steeds grotere aanhang, wat negatieve gevolgen kan hebben voor de samenleving. Zo zijn er, mede dankzij complotcontent op YouTube, steeds meer mensen die beginnen te twijfelen aan de wetenschap. Wanneer zulke twijfels zich voordoen bij belangrijke onderwerpen, zoals het wel of niet innemen van het vaccin tegen het coronavirus, kan dit gevaarlijke gevolgen hebben voor de maatschappij. Zo is meer dan de helft van de Amerikaanse populatie twijfelachtig over - of zelf definitief tegen - het nemen van het coronavaccin \citep{rosenbaum2021escaping}. Dit onderzoek is gebaseerd op een aflevering van VPRO's \textit{Zondag met Lubach}, waarin eenzelfde idee op kleinere schaal werd uitgevoerd \citep{lubach_2020}. De uiterst interessante resultaten van dat experiment hebben mij gemotiveerd om het in grotere mate te onderzoeken. 
Er is al onderzoek gedaan naar filterbubbels en complot-content op YouTube, maar deze onderzoeken houden zich niet bezig met hoe snel een dergelijke bubbel ontstaat. Daarnaast kijken deze onderzoeken specifiek naar aanbevelingen op content, waarbij de aanbevelingen gebaseerd worden op de gelijkenis van de video’s en niet op het kijkgedrag van gebruikers. 

\subsection{Research question}
This research will focus on the following research question:
\textit{What is the impact of different watch strategies on the number of conspiracy videos that have to be watched until a user's YouTube-recommendations start preferring conspiracy content?} Wherein 'preferring' will be defined as the amount of conspiracy videos present in the recommendations being significantly higher than that of the baseline.

\vspace{0.1in}
\noindent In order to answer the research question, three sub-questions will have to be answered. These questions are the following:
\begin{itemize}
    \item With which watch strategy do YouTube recommendations start preferring conspiracy videos the quickest?
    \item How long does it take for a YouTube user to escape a filter bubble, once they find themself in one
    \item What type of classifier performs the best when it comes to labeling conspiracy videos on YouTube?
\end{itemize}

\end{document}